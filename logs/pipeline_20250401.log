ubuntu@hadoop-server:~$ cat logs/pipeline_20250401.log 
===== Pipeline started at Tue Apr  1 16:48:02 UTC 2025 =====
Step 1: Retrieving new token...
Source file: ubuntu@10.10.0.146:/home/ubuntu/files/adminToken.txt
Destination: ubuntu@127.0.0.1:/home/ubuntu/code/files/
Private key: /home/ubuntu/.ssh/id_rsa_scp
Step 2: Running Python script (/home/ubuntu/code/fetch_data.py)...

TOKEN: b525a54514cf9bbc02c1c848203b509a
URL: http://10.10.0.146:7000/admin/analytics?token=b525a54514cf9bbc02c1c848203b509a
{"created":1743470688,"guid":"a7d37738f965a73849b544119cd6f44f4b9fd047092b743e50c04c5b855ed094","record_type":"user","username":"new_user"}
{"created":1743481717,"guid":"b64a523463c7065396e371762cef098da02b94ec7864df789b72e2b2d29bb96a","record_type":"user","username":"farag"}
{"assetId":"06f6fee7-8c4c-49d2-9bf1-24951ae406ef","channelId":"5","created":1743470703,"filename":"06f6fee7-8c4c-49d2-9bf1-24951ae406ef","mediaType":"ready","record_type":"photo","topicId":"12","username":"new_user"}
{"assetId":"7bd06938-592e-480e-8e8e-00640fe3cb0f","channelId":"6","created":1743481733,"filename":"7bd06938-592e-480e-8e8e-00640fe3cb0f","mediaType":"ready","record_type":"photo","topicId":"15","username":"farag"}
{"assetId":"e1aef21d-895d-438d-9355-e126ca772ac8","channelId":"6","created":1743481730,"filename":"e1aef21d-895d-438d-9355-e126ca772ac8","mediaType":"ready","record_type":"photo","topicId":"14","username":"farag"}
{"assetId":"dd91664d-0242-40f6-900f-dcd364fab4ef","channelId":"6","created":1743481728,"filename":"dd91664d-0242-40f6-900f-dcd364fab4ef","mediaType":"ready","record_type":"photo","topicId":"13","username":"farag"}

Step 3: Uploading data to HDFS: /databag-dir/data_20250401.jsonl
Step 4: Running Hadoop MapReduce job with output: /databag-dir/output_20250401
2025-04-01 16:48:57,502 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/ubuntu/code/mapper.py, /home/ubuntu/code/reducer.py, /tmp/hadoop-unjar13144351229329266722/] [] /tmp/streamjob5838314090611634784.jar tmpDir=nullpackageJobJar: [/home/ubuntu/code/mapper.py, /home/ubuntu/code/reducer.py, /tmp/hadoop-unjar13144351229329266722/] [] /tmp/streamjob5838314090611634784.jar tmpDir=null

2025-04-01 16:49:10,349 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /10.0.0.17:8032
2025-04-01 16:49:10,349 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /10.0.0.17:8032
2025-04-01 16:49:15,323 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1743373251093_0007
2025-04-01 16:49:19,269 INFO mapred.FileInputFormat: Total input files to process : 1
2025-04-01 16:49:20,317 INFO mapreduce.JobSubmitter: number of splits:2
2025-04-01 16:49:22,838 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1743373251093_0007
2025-04-01 16:49:22,840 INFO mapreduce.JobSubmitter: Executing with tokens: []
2025-04-01 16:49:25,231 INFO conf.Configuration: resource-types.xml not found
2025-04-01 16:49:25,237 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-04-01 16:49:26,198 INFO impl.YarnClientImpl: Submitted application application_1743373251093_0007
2025-04-01 16:49:26,642 INFO mapreduce.Job: The url to track the job: http://hadoop-server:8088/proxy/application_1743373251093_0007/
2025-04-01 16:49:26,661 INFO mapreduce.Job: Running job: job_1743373251093_0007
2025-04-01 16:50:31,065 INFO mapreduce.Job: Job job_1743373251093_0007 running in uber mode : false
2025-04-01 16:50:31,110 INFO mapreduce.Job:  map 0% reduce 0%
2025-04-01 16:51:42,487 INFO mapreduce.Job:  map 100% reduce 0%
2025-04-01 16:52:29,164 INFO mapreduce.Job:  map 100% reduce 100%
2025-04-01 16:52:31,372 INFO mapreduce.Job: Job job_1743373251093_0007 completed successfully
2025-04-01 16:52:32,557 INFO mapreduce.Job: Counters: 55
        File System Counters
                FILE: Number of bytes read=322
                FILE: Number of bytes written=839905
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=1899
                HDFS: Number of bytes written=209
                HDFS: Number of read operations=11
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
                HDFS: Number of bytes read erasure-coded=0
        Job Counters 
                Killed map tasks=1
                Launched map tasks=2
                Launched reduce tasks=1
                Data-local map tasks=2
                Total time spent by all maps in occupied slots (ms)=129455
                Total time spent by all reduces in occupied slots (ms)=43101
                Total time spent by all map tasks (ms)=129455
                Total time spent by all reduce tasks (ms)=43101
                Total vcore-milliseconds taken by all map tasks=129455
                Total vcore-milliseconds taken by all reduce tasks=43101
                Total megabyte-milliseconds taken by all map tasks=132561920
                Total megabyte-milliseconds taken by all reduce tasks=44135424
        Map-Reduce Framework
                Map input records=6
                Map output records=10
                Map output bytes=296
                Map output materialized bytes=328
                Input split bytes=210
                Combine input records=0
                Combine output records=0
                Reduce input groups=3
                Reduce shuffle bytes=328
                Reduce input records=10
                Reduce output records=4
                Spilled Records=20
                Shuffled Maps =2
                Failed Shuffles=0
                Merged Map outputs=2
                GC time elapsed (ms)=1258
                CPU time spent (ms)=30060
                Physical memory (bytes) snapshot=750465024
                Virtual memory (bytes) snapshot=8190656512
                Total committed heap usage (bytes)=495976448
                Peak Map Physical memory (bytes)=278097920
                Peak Map Virtual memory (bytes)=2729308160
                Peak Reduce Physical memory (bytes)=196210688
                Peak Reduce Virtual memory (bytes)=2732937216
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters 
                Bytes Read=1689
        File Output Format Counters 
                Bytes Written=209
2025-04-01 16:52:32,558 INFO streaming.StreamJob: Output directory: /databag-dir/output_20250401
Step 5: Fetching output from HDFS to /home/ubuntu/code/files/output_local_20250401
Step 6: Sending email with report...
[('new_user', '2'), ('photo_count', '4'), ('photo_group', 'farag', 'dd91664d-0242-40f6-900f-dcd364fab4ef, e1aef21d-895d-438d-9355-e126ca772ac8, 7bd06938-592e-480e-8e8e-00640fe3cb0f'), ('photo_group', 'new_user', '06f6fee7-8c4c-49d2-9bf1-24951ae406ef')]
Email sent successfully!
===== Pipeline completed successfully at Tue Apr  1 16:53:03 UTC 2025 =====